{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "931790ee",
   "metadata": {
    "id": "32da31fb"
   },
   "source": [
    "# Few Shot Learning- Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580265f1",
   "metadata": {
    "id": "e6db8055"
   },
   "source": [
    "**Notebook內容：**\n",
    "1. 先備知識\n",
    "2. 模型/演算法\n",
    "3. 參考資料(連結+連結說明)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc0018",
   "metadata": {
    "id": "d8a26917"
   },
   "source": [
    "## 1.先備知識"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e771a98e",
   "metadata": {
    "id": "7b01dfbf"
   },
   "source": [
    "### 1.1 Few Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59746df",
   "metadata": {
    "id": "JROUouQTuHV9"
   },
   "source": [
    "* 因為target訓練資料不足，而導致模型訓練有over-fitting, under-fitting的情況\n",
    "* 訓練框架: Transfer Learning\n",
    "    * 透過在source dataset訓練而學會較好的特徵萃取，在target資料上期望能取得更好的performance\n",
    "* 訓練框架: Meta Learning\n",
    "    * 將source dataset形成多個task學習好的特徵比較或者好的更新方式等等，在target資料上期望能取得更好的performance\n",
    "* 作法: Metric based Transfer Learning/Meta Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb50ce",
   "metadata": {
    "id": "fbee2a59"
   },
   "source": [
    "### 1.2 Metric base前情提要"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae861b",
   "metadata": {
    "id": "ZLFx6eCDuC3r"
   },
   "source": [
    "* 混合similarity、distance這些固定準則加入network中估計output、而非直接學習類別本身\n",
    "* 將data embed到一個高維空間中\n",
    "* 同種類相似度高(距離近)，不同種類相似度低(距離遠)\n",
    "* 比較種類參考資料(support)和待測資料(query)間的距離或相似度就能預測待測資料屬於哪個種類"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedb67c7",
   "metadata": {
    "id": "85d2e2ea"
   },
   "source": [
    "## 2.模型/演算法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693a14cf",
   "metadata": {
    "id": "psgdpijySorn"
   },
   "source": [
    "這邊使用的model都經過兩個步驟: \n",
    "* Embedding Learning- 學習使用backbone model基本特徵萃\n",
    "* Adaptation- 讓backbone model及head model更適應於target data的訓練\n",
    "\n",
    "這邊分Head, Model , Loss三部分介紹可能增加小資料訓練強度的方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6e2a5b",
   "metadata": {
    "id": "29c45c65"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93515151",
   "metadata": {
    "id": "9f3c5b97"
   },
   "source": [
    "### 2.1 Cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68092a9",
   "metadata": {
    "id": "d5ed4719"
   },
   "source": [
    "一些可能的building blocks，這邊是從頭train model，:\n",
    "* 有normalization, activation, pooing 的Convolution層\n",
    "* 有normalization, activation 的Dense層"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d206e3e5",
   "metadata": {
    "id": "7291ce8d"
   },
   "outputs": [],
   "source": [
    "# convolution cell\n",
    "class conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super().__init__()\n",
    "        self.cell=nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, 3, 1, 1),\n",
    "            nn.InstanceNorm2d(ch_out),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        return self.cell(x)\n",
    "    \n",
    "# dense cell: \n",
    "class dense(nn.Module):\n",
    "    def __init__(self,ch_in=512,ch_out=512,squeeze_input=False):\n",
    "        super().__init__()\n",
    "        self.cell=nn.Sequential(\n",
    "            nn.Linear(ch_in, ch_out),\n",
    "            nn.BatchNorm1d(ch_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.squeeze_input=squeeze_input\n",
    "    def forward(self,x):\n",
    "        if self.squeeze_input:\n",
    "            return self.cell(x.squeeze())\n",
    "        return self.cell(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa72f4f",
   "metadata": {
    "id": "5be134bb"
   },
   "source": [
    "### 2.2 Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad72bd8",
   "metadata": {
    "id": "06806ab6"
   },
   "source": [
    "* 做feature extraction的部分。\n",
    "\n",
    "* 這邊簡單兜一個CNN而已，也可以使用一些pre-train backbone, 如efficient net, resnet等等\n",
    "\n",
    "* 簡單CNN結構: \n",
    "    * 數層Convolution cell\n",
    "    * 用Global average pooling平均每個feature map的local訊息\n",
    "    * 最後加一個dense cell投射到指定的latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dfda971",
   "metadata": {
    "id": "76f8096a"
   },
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features=3,\n",
    "                 latent_features=3,\n",
    "                 hidden_featrues=(64,128,256)):\n",
    "        super().__init__()\n",
    "        self.blocks = nn.Sequential(\n",
    "            conv(3,hidden_featrues[0]),\n",
    "            *[conv(ch1, ch2) for ch1,ch2 in zip(hidden_featrues[:-1],hidden_featrues[1:])],\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            dense(hidden_featrues[-1],latent_features,squeeze_input=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.blocks(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4570df",
   "metadata": {
    "id": "9c3c1988"
   },
   "source": [
    "### 2.3 Head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d3eb82",
   "metadata": {
    "id": "c20d74aa"
   },
   "source": [
    "* 將latent space做切分用以分類的Output layer\n",
    "* 不同的方法在output head差很多:\n",
    "    1. Transfer Learning:\n",
    "        * 普通的dense layer output head, 將weight與前層feature相乘加上bias而已，可能會使用各種loss訓練，torch的CCE有附softmax\n",
    "        * nn.Linear\n",
    "    3. Siamese Networks:\n",
    "        * 不需要weight, 因為計算相似度或距離的來源是support照片本萃取出的latent vector\n",
    "        * 這邊不放nn.Module，在Model上定義計算方式即可\n",
    "    4. N-Way-K-Shot Support(以Prototypical Network為例)\n",
    "        * 不需要weight, 因為計算相似度或距離的來源是support照片本萃取出的latent vector\n",
    "        * 這邊不放nn.Module，在Model上定義計算方式即可\n",
    "    2. Baseline++:\n",
    "        * 每個類別有自己代表的latent vector,將latent vector與前層feature計算相似度或距離(metric)，可能會使用各種loss訓練\n",
    "        * CosineLayer(客製化) - 這邊使用cosine simmilarity做為metric，另有euclidien distance供參考"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e85bbb",
   "metadata": {},
   "source": [
    "**這邊有提供計算distance的方式**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4cba3eb",
   "metadata": {
    "id": "ce80211a"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# 計算cosine similarity\n",
    "def cosine(x,w):\n",
    "    return F.linear(F.normalize(x,dim=-1), F.normalize(w,dim=-1))\n",
    "# 也可以用其他metric如eucidien distance, 不過要配合不同的loss\n",
    "def euc_dist(x,w):\n",
    "    return F.pairwise_distance(x, w, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad7e253",
   "metadata": {
    "id": "65da6eef"
   },
   "source": [
    "### 2.4 Model\n",
    "* 組合各部件為完整分類模型\n",
    "* 不同方法在output上有差別:\n",
    "    * Siamese Networks: \n",
    "        * 將兩個data丟進backbone得到latetent\n",
    "        * 將兩個latent計算相似度做為output\n",
    "        * output logits是相似度\n",
    "    * Prototypical Network: \n",
    "        * 將N*K support還有query全部丟進backbone得到latent\n",
    "        * 每個support做K shot平均成為prototype\n",
    "        * 將每個prototype與query計算相似度做為output\n",
    "    * baseline++ (與Transfer Learning一樣): \n",
    "        * 將backbone output接至head\n",
    "        * output logits在baseline++上是相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d68d8a8",
   "metadata": {
    "id": "069ce7f7"
   },
   "outputs": [],
   "source": [
    "WAYS=6\n",
    "SHOTS=5\n",
    "\n",
    "class ClasModel(nn.Module):\n",
    "    def __init__(self,ways,shots,backbone,head,metric=cosine):\n",
    "        super().__init__()\n",
    "        self.ways=ways\n",
    "        self.shots=shots\n",
    "\n",
    "        self.backbone=backbone\n",
    "        self.head=head\n",
    "        self.metric=metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c50942",
   "metadata": {
    "id": "961436ea"
   },
   "source": [
    "#### 2.4.1 Fine-tuning(對照組, 作為baseline): (Transfer Learning)\n",
    "* Embedding Learning- \n",
    "    * 透過source dataset 訓練所有類別的分類\n",
    "    * 目標為區分source dataset所有類別\n",
    "* Adaptation- 換掉head, 再透過target dataset training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0536ec16",
   "metadata": {
    "id": "jT2Ll9cdZaSn"
   },
   "outputs": [],
   "source": [
    "class Baseline(ClasModel):\n",
    "    def __init__(self,ways,backbone,head):\n",
    "        assert(backbone is not None)\n",
    "        super().__init__(ways,None,backbone,head)\n",
    "    def forward(self,data,label=None):\n",
    "        # Transfer Learing: backbone+ output head\n",
    "        hidden=self.backbone(data)\n",
    "        logits=self.head(hidden)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b5184a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 429,
     "status": "ok",
     "timestamp": 1648267670434,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "babdf1c3",
    "outputId": "0653651d-838d-4178-93ec-50e7c1452e2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent shape(One batch): torch.Size([8, 2])\n",
      "Output shape: torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "# Vanilla Transfer Learning\n",
    "latent_dims=2\n",
    "backbone=FeatureExtractor(latent_features=latent_dims)\n",
    "head=nn.Linear(latent_dims,WAYS)\n",
    "mode=\"transfer\"\n",
    "model=Baseline(WAYS,backbone,head)\n",
    "\n",
    "x=torch.empty((8,3,28,28),dtype=torch.float32)\n",
    "logit=model(x)\n",
    "print(\"Latent shape(One batch):\",model.backbone(x).shape)\n",
    "print(\"Output shape:\",logit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c03bd5",
   "metadata": {
    "id": "598e62cc"
   },
   "source": [
    "#### 2.4.2 Siamese Networks: (Metric-based Meta Learning)\n",
    "* Embedding Learning-  \n",
    "    * 將source dataset中資料拆成兩兩一對的pairs training\n",
    "    * 目標是訓練萃取後特徵的對比，同class相近，異class遠離\n",
    "* Adaptation- 無，直接比較target dataset資料中support與query的部分透過backbone萃取的特徵是否足夠相近\n",
    "\n",
    "<img src=https://i.imgur.com/jK98zOa.png  width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55f1eab8",
   "metadata": {
    "id": "WGqAByshaCoy"
   },
   "outputs": [],
   "source": [
    "class SiameseNet(ClasModel):\n",
    "    def __init__(self,backbone,metric=cosine):\n",
    "        super().__init__(2,None,backbone,None,metric)\n",
    "    def forward(self,data,label=None):\n",
    "        # 進Embedding\n",
    "        latent=[*map(self.backbone,data.transpose(0,1))]\n",
    "        # latent算metric 這邊用cosine\n",
    "        logits=torch.stack([*map(self.metric,latent[0],latent[1])],dim=0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7a67784",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 287,
     "status": "ok",
     "timestamp": 1648267899776,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "78094ccf",
    "outputId": "20b6965f-aaec-4783-c780-b4fbb9488fa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latents shape(One meta batch): torch.Size([2, 5])\n",
      "Output shape: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "# Siamese Networks with cosine metric\n",
    "latent_dims=5\n",
    "backbone=FeatureExtractor(latent_features=latent_dims)\n",
    "mode=\"siamese\"\n",
    "model=SiameseNet(backbone,cosine)\n",
    "x=torch.empty((8,2,3,28,28),dtype=torch.float32)\n",
    "logit=model(x)\n",
    "print(\"Latents shape(One meta batch):\",model.backbone(x[0]).shape)\n",
    "print(\"Output shape:\",logit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cf3648",
   "metadata": {
    "id": "faeda1f3"
   },
   "source": [
    "#### 2.4.3 Prototypical Network: (Metric-based Meta Learning)\n",
    "* Embedding Learning-  將source dataset中資料拆成好幾個task\n",
    "    * 每個task有N個class分別抽K個資料\n",
    "    * 目標是訓練萃取後特徵的對比，同class相近(要是N個類別內最近的)，異class遠離\n",
    "* Adaptation- 無，直接比較target dataset資料中support與query的部分\n",
    "\n",
    "<img src=https://i.imgur.com/wLdemUU.png  width=\"600\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a434ea65",
   "metadata": {
    "id": "n7LZ6tTvbHW-"
   },
   "outputs": [],
   "source": [
    "class PrototypicalNet(ClasModel):\n",
    "    def __init__(self,ways,shots,backbone,metric=cosine):\n",
    "        super().__init__(ways,shots,backbone,None,metric)\n",
    "    def meta_forward(self,dataset,label=None):\n",
    "        # 全部進embedding\n",
    "        latent=torch.stack([*map(self.backbone,dataset)],dim=0)\n",
    "        latent_q,latent_s=latent[:,self.ways*self.shots:],latent[:,:self.ways*self.shots]\n",
    "        # 計算 prototypes\n",
    "        latent_proto=torch.stack([torch.mean(l,dim=1) for l in torch.split(latent_s,self.shots,dim=1)],dim=1)\n",
    "        logits=torch.cat([*map(self.metric,latent_q,latent_proto)],dim=0)\n",
    "        return logits\n",
    "    def save_prototypes(self,dataset):\n",
    "        with torch.no_grad():\n",
    "            latent_s=self.backbone(dataset)\n",
    "            self.latent_proto=torch.stack([torch.mean(l,dim=0) for l in torch.split(latent_s,self.shots,dim=0)],dim=0).detach()\n",
    "    def forward(self,data,label=None):\n",
    "        latent_q=self.backbone(data)[:,np.newaxis,...]\n",
    "        logits=torch.cat([self.metric(self.latent_proto,qq).transpose(0,1) for qq in latent_q],dim=0)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e99462",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 837,
     "status": "ok",
     "timestamp": 1648268184343,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "ddee2aee",
    "outputId": "73adbd2a-2672-428a-d0c3-3556d384a435"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latents shape(One meta batch): torch.Size([31, 5])\n",
      "Output shape: torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "# Prototypical Network with cosine metric\n",
    "\n",
    "mode=\"proto\"\n",
    "model=PrototypicalNet(WAYS,SHOTS,backbone,cosine)\n",
    "x=torch.empty((8,WAYS*SHOTS+1,3,28,28),dtype=torch.float32)\n",
    "logit=model.meta_forward(x)\n",
    "print(\"Latents shape(One meta batch):\",model.backbone(x[0]).shape)\n",
    "print(\"Output shape:\",logit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499e16b",
   "metadata": {
    "id": "de3410cf"
   },
   "source": [
    "#### 2.4.4 Baseline++ : (Metric-based Transfer Learning)\n",
    "* Embedding Learning- \n",
    "    * 透過source dataset training,訓練所有類別的分類\n",
    "    * 目標為區分source dataset所有類別在latent space中的latent vector，各類別相應的latent vector會在過程中被訓練及儲存成weight\n",
    "* Adaptation- 換掉head(或加上更多weight), 再透過target dataset training訓練新的類別在latent space上相應的latent vector位置\n",
    "    * 不同類別latent vector間的distance要拉開\n",
    "    * 或者是同類別latent vector間的similarity要拉近\n",
    "\n",
    "<img src=https://i.imgur.com/SIGtTdV.png  width=\"700\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfd0cf",
   "metadata": {
    "id": "WU7a-k3ytEhN"
   },
   "source": [
    "#### Supp. Cosine Similarity Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af815b6",
   "metadata": {
    "id": "dleYW5NdvVwz"
   },
   "source": [
    "* 來自於Ring Loss, 就是對latent vector與output layer weight(support latent vector)算cosine simmilarity後再做Softmax\n",
    "* 與原本dense+softmax相比，若將dense的矩陣乘法改為normalized矩陣相乘則等於計算cosine similarity，其效果是可以減少數量多的類別可能形成的domination\n",
    "* 計算cosine 後再使用softmax\n",
    "\n",
    "<img src=https://i.imgur.com/WU0MXS5.png  width=\"600\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c6d7d2",
   "metadata": {
    "id": "un0afWIYUJU_"
   },
   "source": [
    "* Layer計算公式:$ $\n",
    "    * Dense Layer: $h=W^Tx+b$\n",
    "        * $x\\in N^{1\\times D}$是latent vector\n",
    "        * $W\\in N^{N\\times D}$為weight\n",
    "        * b是bias, \n",
    "        * $h\\in N^{1\\times N}$是logit\n",
    "    * Cosine Layer: $h=\\frac{W^Tx}{|W||x|}=cos{\\phi} $\n",
    "        * h依然是logit，但可看作x與W裡面每個latent vector夾角$\\phi$取cosine的值，也是相似度\n",
    "        * $\\phi\\in N^{1\\times N}$是夾角，相似度越大，夾角越小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d0a50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine的layer\n",
    "class MetricLayer(nn.Module):\n",
    "    def __init__(self, n_in_features,n_out_features=10,metric=cosine):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(n_out_features, n_in_features))\n",
    "        nn.init.xavier_uniform_(self.weight,gain=1.0)\n",
    "        self.metric=metric\n",
    "    def forward(self,x):\n",
    "        return self.metric(x,self.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52e9dc0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1648267787561,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "c7611dcf",
    "outputId": "40c28b32-ebbe-4795-a68e-8828163a909b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent shape(One batch): torch.Size([8, 5])\n",
      "Output shape: torch.Size([8, 6])\n"
     ]
    }
   ],
   "source": [
    "# Baseline++ with cosine metric\n",
    "\n",
    "backbone=FeatureExtractor(latent_features=latent_dims)\n",
    "head=MetricLayer(latent_dims,WAYS,cosine)\n",
    "model=Baseline(WAYS,backbone,head)\n",
    "x=torch.empty((8,3,28,28),dtype=torch.float32)\n",
    "logit=model(x)\n",
    "print(\"Latent shape(One batch):\",model.backbone(x).shape)\n",
    "print(\"Output shape:\",logit.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0004ad",
   "metadata": {
    "id": "ba59b1c2"
   },
   "source": [
    "### 2.5 Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12867f",
   "metadata": {
    "id": "903096e9"
   },
   "source": [
    "* 定義計算output logits與label的誤差的方式。\n",
    "* 這邊提供幾種loss:\n",
    "    * Categorical Cross Entropy(CCE) -> (torch原生)可以給transfer learning, baseline++, prototypical network用\n",
    "    * Focal Loss -> 加強正確類別的權重，可以給transfer learning, baseline++, prototypical network用\n",
    "    * Contrastive Loss -> 可以給Siamese Network用，但這邊是給euclidien distance metric用的，若是cosine similarity則可直接用BCE\n",
    "    * Add Margin Loss -> 人臉辨識家族CosineFace用的loss，拉開不同class的cosine值，給cosine metric用: baseline++, prototypical network\n",
    "    * Arc Margin Loss -> 人臉辨識家族ArcFace用的loss，拉開不同class的徑度值(cosine裡面的那個角度)，給cosine metric用: baseline++, prototypical network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fca6cb8",
   "metadata": {
    "id": "RSbSosGPBVAq"
   },
   "source": [
    "### 2.5.1 Special Loss for Transfer Learning\n",
    "* Focal Loss: 降低easy case中loss gradient,增加hard case中loss gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e45a4a",
   "metadata": {
    "id": "cfiPnBBqN7Pw"
   },
   "source": [
    "<img src=https://i.imgur.com/u9OUrX2.png  width=\"400\" height=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7e3ca44",
   "metadata": {
    "id": "mX2dJy6aBTQx"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2, eps=1e-10):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.eps = torch.tensor(eps,dtype=torch.float32)\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "    def forward(self,  y_pred,y_true):\n",
    "        # 計算cross entropy\n",
    "        logp = self.ce(y_pred+self.eps, y_true)\n",
    "        # 計算乘上gamma次方後的entropy反方機率(將對比放大)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8182711",
   "metadata": {
    "id": "kee_b_-5__Db"
   },
   "source": [
    "### 2.5.2 Loss for Siamese Netwrok\n",
    "* Contrastive Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff3e7b8",
   "metadata": {
    "id": "s2Gx0QQk__SC"
   },
   "outputs": [],
   "source": [
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self,m=1):\n",
    "        super().__init__()\n",
    "        self.m=m\n",
    "        self.activation=torch.sigmoid\n",
    "        self.loss_fn=nn.BCELoss()\n",
    "        self.z=torch.tensor(0.,dtype=torch.float32,requires_grad=False)\n",
    "    def forward(self, y_pred,y_true):\n",
    "        # 兩者同組時，算square\n",
    "        # 兩者不同組時，算margin- distance值，若distance大於margin則不用再拉伸兩者distance\n",
    "        loss=torch.mean(y_true * torch.square(y_pred)+ \n",
    "                        (1 - y_true)* torch.square(torch.maximum(self.m - y_pred, self.z)\n",
    "                        ),dim=-1,keepdims=True)\n",
    "        return loss.mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edad622",
   "metadata": {
    "id": "E_Aizthes4sL"
   },
   "source": [
    "### 2.5.3 Loss for Cosine logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806d8cc3",
   "metadata": {
    "id": "qd_MiLrGuVuI"
   },
   "source": [
    "前述Baseline++是使用Metric based的方法來對待測image的latent vector與各類別support訓練出來的latent vector算cosine simillarity，並且在target task時可以訓練target類別的support latent vector。\n",
    "\n",
    "那這個cosine similarity 也可以有更多種方式來緩和資料不平衡的影響及增強類別的區辨。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779cc241",
   "metadata": {
    "id": "ojSHRGNvv9HV"
   },
   "source": [
    "*  CosineMargin Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58aacb6",
   "metadata": {
    "id": "WY2_kDoYwHHd"
   },
   "source": [
    "* 出自CosineFace, 先計算cosine simmilarity\n",
    "* 在正確類別cosine值扣掉一個margin，使得訓練變得更困難，也使得每個類別的區分更明顯\n",
    "(增加Way數大的時候的準確度)\n",
    "\n",
    "<img src=https://i.imgur.com/75WvROU.png  width=\"600\" height=\"300\">\n",
    "\n",
    "(借用L-Softmax的圖形)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7a423da",
   "metadata": {
    "id": "UhOEaEtgAVzb"
   },
   "outputs": [],
   "source": [
    "class AddMarginLoss(nn.Module):\n",
    "    def __init__(self, s=15.0, m=0.40,loss_fn=FocalLoss()):\n",
    "        super().__init__()\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.loss_fn=loss_fn\n",
    "    def forward(self, cosine, label=None):\n",
    "        # 扣掉對cosine的margin\n",
    "        cos_phi = cosine - self.m\n",
    "        # 將onehot沒選中的類別不套用margin，onehot選中的套用margin     \n",
    "        one_hot=F.one_hot(label, num_classes=- 1).to(torch.float32)\n",
    "        metric = (one_hot * cos_phi) + ((1.0 - one_hot) * cosine)\n",
    "        # 將輸出對比放大\n",
    "        metric *= self.s\n",
    "        return self.loss_fn(metric,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c985af1",
   "metadata": {
    "id": "69rzESoFyUq8"
   },
   "source": [
    "* ArcMargin Loss\n",
    "    * 出自ArcFace, 要先計算cosine simmilarity\n",
    "    * 將正確類別cosine值轉成arc(角度)再加上一個margin，使得訓練變得更困難，也使得每個類別的區分更明顯\n",
    "    * 另外也有其他使用margin的loss，都是在增加不同類別latent vecor間的角度，以下為列表\n",
    "    <img src=https://i.imgur.com/SHyaRnc.png  width=\"400\" height=\"150\">\n",
    "    * 使用margin對角度的影響如示意圖\n",
    "    <img src=https://i.imgur.com/h1dFJ8z.png  width=\"500\" height=\"150\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e54cd241",
   "metadata": {
    "id": "35090ea6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class ArcMarginLoss(AddMarginLoss):\n",
    "    def __init__(self, s=32.0, m=0.40, easy_margin=False,loss_fn=FocalLoss()):\n",
    "        super().__init__(s,m,loss_fn)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "\n",
    "        # make the function cos(theta+m) monotonic decreasing while theta in [0°,180°]\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        self.eps = 1e-6\n",
    "    def forward(self, cosine, label=None):\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2) + self.eps)\n",
    "        # cos(phi)cos(m)-sin(phi)sin(m)變成cos(phi + m)\n",
    "        # 這個margin加上去使得角度phi需要更小才能使指定類別在softmax(cos(phi))時最大\n",
    "        cos_phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            # cosine如果不夠大就不用不套用phi margin\n",
    "            cos_phi = torch.where(cosine > 0, cos_phi, cosine)\n",
    "        else:\n",
    "            # 更加嚴格，若cosine(phi)大於margin則套用phi margin規則\n",
    "            #          若cosine(phi)小於margin則套用cosine margin規則\n",
    "            cos_phi = torch.where(cosine > self.th, cos_phi, cosine - self.mm)\n",
    "            \n",
    "        # 將onehot沒選中的類別不套用margin，onehot選中的套用margin    \n",
    "        one_hot=F.one_hot(label, num_classes=- 1).to(torch.float32)\n",
    "        metric = (one_hot * cos_phi) + ((1.0 - one_hot) * cosine)\n",
    "        # 將輸出對比放大\n",
    "        metric *= self.s\n",
    "        return self.loss_fn(metric,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812aec0",
   "metadata": {
    "id": "39712ff2"
   },
   "source": [
    "試看loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7df53dff",
   "metadata": {
    "id": "1c24f3f1"
   },
   "outputs": [],
   "source": [
    "cce=nn.CrossEntropyLoss()\n",
    "focal_cce=FocalLoss(2,SHOTS)\n",
    "contrastive=ContrastiveLoss(m=1)\n",
    "addmarginloss=AddMarginLoss(s=2.0, m=0.40)\n",
    "arcmarginloss=ArcMarginLoss(s=2.0, m=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3adf4470",
   "metadata": {
    "id": "1c504eed"
   },
   "outputs": [],
   "source": [
    "yy=torch.tensor([0,1,2,3])\n",
    "y_gt=F.one_hot(yy, num_classes=- 1).to(torch.float32)\n",
    "y_best=y_gt-0.5+torch.randn((4,4),dtype=torch.float32)/100\n",
    "y_good=y_gt-0.5+torch.randn((4,4),dtype=torch.float32)/10\n",
    "y_noisy=y_gt-0.5+torch.randn((4,4),dtype=torch.float32)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "116aa5bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 384,
     "status": "ok",
     "timestamp": 1648268745587,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "IN-bPLJvXc-D",
    "outputId": "d2359bd0-c3ef-428e-8c49-0042bda74733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2272)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive(y_gt,y_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88cb539f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1648268746261,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "82a71bfc",
    "outputId": "05f2d2cb-d85c-45b1-fc4c-cfb6bde7b350"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdcf40e3c70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,4,1);plt.imshow(y_gt)\n",
    "plt.subplot(1,4,2);plt.imshow(y_best)\n",
    "plt.subplot(1,4,3);plt.imshow(y_good)\n",
    "plt.subplot(1,4,4);plt.imshow(y_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ffe6737",
   "metadata": {
    "id": "5e9602ca"
   },
   "outputs": [],
   "source": [
    "loss_cce=[cce(pred,yy).item() for pred in [y_gt,y_best,y_good,y_noisy]]\n",
    "loss_focal=[focal_cce(pred,yy).item() for pred in [y_gt,y_best,y_good,y_noisy]]\n",
    "loss_add=[addmarginloss(pred,yy).item() for pred in [y_gt,y_best,y_good,y_noisy]]\n",
    "loss_arc=[arcmarginloss(pred,yy).item() for pred in [y_gt,y_best,y_good,y_noisy]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8112f1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1648268781216,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "5ef48d2a",
    "outputId": "a4c752b2-188d-4e2e-f12d-b8c96c05d861"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best-------------good-------------noisy\n",
      "CCE: [0.7436683773994446, 0.7445589303970337, 0.7814091444015503, 0.8011915683746338]\n",
      "Focal: [0.2046871930360794, 0.20526303350925446, 0.22975283861160278, 0.24342457950115204]\n",
      "Addmargin: [0.1450444757938385, 0.14594729244709015, 0.18906809389591217, 0.28135576844215393]\n",
      "Arcmargin: [0.04045689105987549, 0.13413764536380768, 0.17874965071678162, 0.25891777873039246]\n"
     ]
    }
   ],
   "source": [
    "print(\"best-------------good-------------noisy\")\n",
    "print(\"CCE:\",loss_cce)\n",
    "print(\"Focal:\",loss_focal)\n",
    "print(\"Addmargin:\",loss_add)\n",
    "print(\"Arcmargin:\",loss_arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "251fb1ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 323,
     "status": "ok",
     "timestamp": 1648268817078,
     "user": {
      "displayName": "黃書璵",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "16626369651643867989"
     },
     "user_tz": -480
    },
    "id": "1b455b9f",
    "outputId": "4df3f3ab-0b75-4820-bf1d-5dc67d2b2002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'normalized loss')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhN5/7//9cWkXmSFqFBiCExVYWKWVXVTOdSpYbWaY2hyulgpv1StHpqOjVU6+igzqFXyzGXqik4lAgiKm2pKpKgEuT+/dGf/bEbKpska0mej+va17X3Gu71XlnX3vuVe91rbYcxxggAAMCGilhdAAAAwI0QVAAAgG0RVAAAgG0RVAAAgG0RVAAAgG0RVAAAgG0RVAAAgG0RVAAAgG0VtbqA25GVlaWff/5ZAQEBcjgcVpcDAABywBij9PR0lS5dWkWK/HWfyR0dVH7++WeFh4dbXQYAALgFKSkpuueee/5ymTs6qAQEBEj6Y0cDAwMtrgYAAOREWlqawsPDnd/jf+WODipXT/cEBgYSVAAAuMPkZNgGg2kBAIBtEVQAAIBtEVQAAIBt3dFjVHLCGKPLly/rypUrVpeCPObh4aGiRYtyqToAFCAFOqhkZmbq+PHjunDhgtWlIJ/4+voqLCxMxYoVs7oUAEAuKLBBJSsrS8nJyfLw8FDp0qVVrFgx/tMuwIwxyszM1K+//qrk5GRVqlTppjcRAgDYX4ENKpmZmcrKylJ4eLh8fX2tLgf5wMfHR56envrhhx+UmZkpb29vq0sCANymAv8vJ/9VFy4cbwAoWPhUBwAAtkVQgSVGjRqle++91+oyAAA2V2DHqPyV9tM35du2lvdvlG/bupMMHTpU/fv3t7oMAIDN0aNSAFy6dMnqEpwyMzNztJy/v79CQ0PzuBoAwJ2OoGJDK1asUKNGjRQcHKzQ0FC1a9dOSUlJkqSjR4/K4XDo008/VbNmzeTt7a2PPvpIkjR37lxVq1ZNXl5eCgsLU79+/ZxtOhwOzZo1S+3atZOvr6+ioqL03Xff6fDhw2rWrJn8/PwUGxvr3I4kJSUlqWPHjipZsqT8/f1Vt25drV692qXW8uXLa9y4cerRo4eCgoLUp08fSdKcOXOcV1x17txZU6ZMUXBwsHO9P5/66dGjhzp16qTJkycrLCxMoaGheumll2wVwgAA+Y+gYkPnz59XXFyctm/frjVr1qhIkSLq3LmzsrKynMu88sorGjBggBISEtSqVSvNmDFDL730kp5//nnt3btXy5YtU2RkpEu7Y8eO1bPPPqvdu3eratWq6tKli1544QWNGDFCO3bskCSXcHPu3Dm1adNGq1ev1q5du9SqVSu1b99ex44dc2l30qRJql69uuLj4/X666/r22+/Vd++fTVw4EDt3r1bLVu21Pjx42+63+vWrVNSUpLWrVunBQsWaP78+Zo/f/5t/CUBAHe6QjlGxe4effRRl9cffPCBSpQoof3798vf31+SNGjQID3yyCPOZcaNG6chQ4Zo4MCBzml169Z1aee5557TE088IemPoBMbG6vXX39drVq1kiQNHDhQzz33nHP5WrVqqVatWi7bWLp0qZYtW+YSaB544AENHTrU+fq1115T69atndMqV66szZs368svv/zL/Q4JCdF7770nDw8PVa1aVW3bttWaNWucvTQACq/8HFsIV1aPtaRHxYaSkpLUpUsXVahQQYGBgYqIiJAkl56MmJgY5/OTJ0/q559/VosWLf6y3Zo1azqflyxZUpJUo0YNl2kXL15UWlqapD96doYNG6bo6GgFBwfL399fBw4cyNajcm0tkpSYmKh69eq5TPvz6+upVq2aPDw8nK/DwsJ08uTJm64HACi46FGxofbt2ys8PFxz5sxR6dKllZWVperVq7sMVPXz83M+9/HxyVG7np6ezudXf07getOunmJ6+eWXtXLlSk2ePFmRkZHy8fHRY489lm3A7LW1SH/czv7PP1dgjHGrvqv1XHu6CwBQ+BBUbOa3335TQkKCZs2apcaNG0uSNm366y7PgIAAlS9fXmvWrFHz5s1zrZaNGzeqR48e6ty5s6Q/xqwcPXr0putVrVpV27Ztc5l2dQwMAADuIKjYTEhIiEJDQzV79myFhYXp2LFjGj58+E3XGzVqlPr27asSJUqodevWSk9P17fffntb9yqJjIzUF198ofbt28vhcOj111/PUQ9H//791aRJE02ZMkXt27fX2rVr9fXXX/OjkAAAtzFGxWaKFCmixYsXKz4+XtWrV9fgwYM1adKkm67XvXt3TZs2Te+//76qVaumdu3a6dChQ7dVy9SpUxUSEqIGDRqoffv2atWqle67776brtewYUPNnDlTU6ZMUa1atbRixQoNHjyYHwkEALjNYXIyeMCm0tLSFBQUpNTUVAUGBrrMu3jxopKTkxUREcEXpA306dNHBw4c0MaNG/N0Oxx3oGDiqh/r5MVVP3/1/f1nnPpBnpg8ebJatmwpPz8/ff3111qwYIHef/99q8sCANxhCCrIE9u2bdP/+3//T+np6apQoYLeffdd9e7d2+qyAAB3GIIK8sSnn35qdQkAgAKAwbQAAMC2CCoAAMC2CCoAAMC2CCoAAMC2CCoAAMC2CCoAAMC2CCoFwNGjR+VwOLR79+4bLrN+/Xo5HA6dPXs2HytzT/ny5TVt2jSrywAA2EjhvI/KrKb5t60XNuTftu5w27dvl5+fn9VlAABsxPIelZ9++knPPPOMQkND5evrq3vvvVfx8fFWl4VcYozR5cuXc7Ts3XffLV9f3zyuCABwJ7E0qJw5c0YNGzaUp6envv76a+3fv19vv/22goODrSzLcitWrFCjRo0UHBys0NBQtWvXTklJSc7527ZtU+3ateXt7a2YmBjt2rUrWxtfffWVKleuLB8fHzVv3lxHjx51mT9//nwFBwfryy+/VJUqVeTr66vHHntM58+f14IFC1S+fHmFhISof//+unLlinO9jz76SDExMQoICFCpUqXUpUsXnTx50jn/6immlStXKiYmRl5eXtq4caPS09PVtWtX+fn5KSwsTFOnTlWzZs00aNAg57p/PvXjcDj0z3/+U507d5avr68qVaqkZcuW5cafGABwh7A0qLz11lsKDw/XvHnzVK9ePZUvX14tWrRQxYoVrSzLcufPn1dcXJy2b9+uNWvWqEiRIurcubOysrJ0/vx5tWvXTlWqVFF8fLxGjRqloUOHuqyfkpKiRx55RG3atNHu3bvVu3dvDR8+PNt2Lly4oHfffVeLFy/WihUrtH79ej3yyCP66quv9NVXX2nhwoWaPXu2Pv/8c+c6mZmZGjt2rP73v//p3//+t5KTk9WjR49sbQ8bNkwTJ05UQkKCatasqbi4OH377bdatmyZVq1apY0bN2rnzp03/VuMHj1aTzzxhPbs2aM2bdqoa9euOn36tPt/VADAHcnSMSrLli1Tq1at9Pjjj2vDhg0qU6aMXnzxRfXp0+e6y2dkZCgjI8P5Oi0tLb9KzVePPvqoy+sPPvhAJUqU0P79+7V582ZduXJFc+fOla+vr6pVq6Yff/xRf/vb35zLz5gxQxUqVNDUqVPlcDhUpUoV7d27V2+99ZZLu5cuXdKMGTOcwfCxxx7TwoUL9csvv8jf31/R0dFq3ry51q1bpyeffFKS1LNnT+f6V39ssF69ejp37pz8/f2d88aMGaOWLVtKktLT07VgwQItWrRILVq0kCTNmzdPpUuXvunfokePHnr66aclSRMmTND06dO1bds2Pfzwwzn+ewIA7lyW9qgcOXJEM2bMUKVKlbRy5Ur17dtXAwYM0Icffnjd5SdOnKigoCDnIzw8PJ8rzh9JSUnq0qWLKlSooMDAQEVEREiSjh07poSEBNWqVctlLEdsbKzL+gkJCapfv74cDscNl5EkX19fl96rkiVLqnz58i6Bo2TJki6ndnbt2qWOHTuqXLlyCggIULNmzZy1XSsmJsb5/MiRI7p06ZLq1avnnBYUFKQqVarc9G9Rs2ZN53M/Pz8FBAS41AMAKNgsDSpZWVm67777NGHCBNWuXVsvvPCC+vTpoxkzZlx3+REjRig1NdX5SElJyeeK80f79u3122+/ac6cOdq6dau2bt0q6Y/TLsaYm66fk2UkydPT0+W1w+G47rSsrCxJf5ySeuihh+Tv76+PPvpI27dv19KlS521Xevaq3eu1nNtcMppnX9VDwCg4LM0qISFhSk6OtplWlRUVLb/zq/y8vJSYGCgy6Og+e2335SQkKDXXntNLVq0UFRUlM6cOeOcHx0drf/973/6/fffndO2bNni0kZ0dHS2aX9+fSsOHDigU6dO6c0331Tjxo1VtWrVHPVuVKxYUZ6entq2bZtzWlpamg4dOnTbNQEACjZLg0rDhg2VmJjoMu3gwYMqV66cRRVZLyQkRKGhoZo9e7YOHz6stWvXKi4uzjm/S5cuKlKkiHr16qX9+/frq6++0uTJk13a6Nu3r5KSkhQXF6fExEQtWrRI8+fPv+3aypYtq2LFimn69Ok6cuSIli1bprFjx950vYCAAHXv3l0vv/yy1q1bp3379qlnz54qUqRItl4WAACuZWlQGTx4sLZs2aIJEybo8OHDWrRokWbPnq2XXnrJyrIsVaRIES1evFjx8fGqXr26Bg8erEmTJjnn+/v7a/ny5dq/f79q166tV199Ndsg2bJly2rJkiVavny5atWqpZkzZ2rChAm3Xdvdd9+t+fPn67PPPlN0dLTefPPNbCHpRqZMmaLY2Fi1a9dODz74oBo2bKioqCh5e3vfdl0AgILLYXI6oCGPfPnllxoxYoQOHTqkiIgIxcXF3fCqnz9LS0tTUFCQUlNTs50GunjxopKTkxUREcGXoQ2dP39eZcqU0dtvv61evXrlWrscd6Bgaj99k9UlFFrL+zfK9Tb/6vv7zyy/hX67du3Url07q8tAHtu1a5cOHDigevXqKTU1VWPGjJEkdezY0eLKAAB2ZnlQQeExefJkJSYmqlixYqpTp442btyou+66y+qyAAA2RlBBvqhduza/4QQAcJvlP0oIAABwIwQVAABgWwQVAABgWwQVAABgWwQVAABgWwQVAABgWwQVGzLG6Pnnn1fx4sXlcDi0e/fuPN+mw+HQv//97zzfDgAA7iiU91F58ssn821bn7T7xO11VqxYofnz52v9+vWqUKECN0UDABRahTKo2F1SUpLCwsLUoEEDq0sBAMBSnPqxmR49eqh///46duyYHA6Hypcvr4yMDA0YMEAlSpSQt7e3GjVqpO3bt7ust2/fPrVt21aBgYEKCAhQ48aNlZSUJEnavn27WrZsqbvuuktBQUFq2rSpdu7cacXuAQDgFoKKzbzzzjsaM2aM7rnnHh0/flzbt2/XsGHDtGTJEi1YsEA7d+5UZGSkWrVqpdOnT0uSfvrpJzVp0kTe3t5au3at4uPj1bNnT12+fFmSlJ6eru7du2vjxo3asmWLKlWqpDZt2ig9Pd3KXQUA4KY49WMzQUFBCggIkIeHh0qVKqXz589rxowZmj9/vlq3bi1JmjNnjlatWqUPPvhAL7/8sv7xj38oKChIixcvlqenpySpcuXKzjYfeOABl23MmjVLISEh2rBhA79cDQCwNXpUbC4pKUmXLl1Sw4YNndM8PT1Vr149JSQkSJJ2796txo0bO0PKn508eVJ9+/ZV5cqVFRQUpKCgIJ07d07Hjh3Ll30AAOBW0aNic8YYSX9cPvzn6Ven+fj4/GUbPXr00K+//qpp06apXLly8vLyUmxsrDIzM/OmaAAAcgk9KjYXGRmpYsWKadOmTc5ply5d0o4dOxQVFSVJqlmzpjZu3KhLly5dt42NGzdqwIABatOmjapVqyYvLy+dOnUqX+oHAOB2EFRszs/PT3/729/08ssva8WKFdq/f7/69OmjCxcuqFevXpKkfv36KS0tTU899ZR27NihQ4cOaeHChUpMTJT0R9hZuHChEhIStHXrVnXt2vWmvTAAANgBQeUO8Oabb+rRRx9Vt27ddN999+nw4cNauXKlQkJCJEmhoaFau3atzp07p6ZNm6pOnTqaM2eOc8zK3LlzdebMGdWuXVvdunVzXuoMAIDdOczVQRB3oLS0NAUFBSk1NVWBgYEu8y5evKjk5GRFRETI29vbogqR3zjuQMHUfvqmmy+EPLG8f6Ncb/Ovvr//jB4VAABgWwQVAABgWwQVAABgWwQVAABgWwQVAABgWwQVAABgWwQVAABgWwQVAABgWwQVAABgWwQVAABgW0WtLsAKyY8+lm/biljyeb5tCwCAgoYeFQAAYFsEFRvKysrSW2+9pcjISHl5eals2bIaP368JOnHH3/UU089peLFi8vPz08xMTHaunWrc93ly5erTp068vb2VoUKFTR69GhdvnzZql0BAOC2FMpTP3Y3YsQIzZkzR1OnTlWjRo10/PhxHThwQOfOnVPTpk1VpkwZLVu2TKVKldLOnTuVlZUlSVq5cqWeeeYZvfvuu2rcuLGSkpL0/PPPS5JGjhxp5S4BAHBLCCo2k56ernfeeUfvvfeeunfvLkmqWLGiGjVqpNmzZ+vXX3/V9u3bVbx4cUlSZGSkc93x48dr+PDhzvUqVKigsWPHatiwYQQVAMAdiaBiMwkJCcrIyFCLFi2yzdu9e7dq167tDCl/Fh8fr+3btztPE0nSlStXdPHiRV24cEG+vr55VjcAAHmBoGIzPj4+tzRP+mNsy+jRo/XII49km+ft7X3btQEAkN8YTGszlSpVko+Pj9asWZNtXs2aNbV7926dPn36uuved999SkxMVGRkZLZHkSIcagDAnYceFZvx9vbWK6+8omHDhqlYsWJq2LChfv31V+3bt0/dunXThAkT1KlTJ02cOFFhYWHatWuXSpcurdjYWL3xxhtq166dwsPD9fjjj6tIkSLas2eP9u7dq3Hjxlm9awAAuI1/s23o9ddf15AhQ/TGG28oKipKTz75pE6ePKlixYrpv//9r0qUKKE2bdqoRo0aevPNN+Xh4SFJatWqlb788kutWrVKdevWVf369TVlyhSVK1fO4j0CAODWOIwxxuoiblVaWpqCgoKUmpqqwMBAl3kXL15UcnKyIiIiGJ9RiHDcgYKp/fRNVpdQaC3v3yjX2/yr7+8/o0cFAADYFkEFAADYFkEFAADYlqVBZdSoUXI4HC6PUqVKWVkSAACwEcsvT65WrZpWr17tfH31ChYAAADLg0rRokXztBflDr6oCbeA4w0ABYvlY1QOHTqk0qVLKyIiQk899ZSOHDlyw2UzMjKUlpbm8rgRT09PSdKFCxdyvWbY19XjffX4AwDubJb2qNx///368MMPVblyZf3yyy8aN26cGjRooH379ik0NDTb8hMnTtTo0aNz1LaHh4eCg4N18uRJSZKvr68cDkeu1g/7MMbowoULOnnypIKDgzmFCAAFhK1u+Hb+/HlVrFhRw4YNU1xcXLb5GRkZysjIcL5OS0tTeHj4DW8YY4zRiRMndPbs2TytG/YRHBysUqVKEUqBAoYbvlnH6hu+WT5G5Vp+fn6qUaOGDh06dN35Xl5e8vLyynF7DodDYWFhKlGihC5dupRbZcKmPD096UkBgALGVkElIyNDCQkJaty4ca626+HhwRcYAAB3IEsH0w4dOlQbNmxQcnKytm7dqscee0xpaWnq3r27lWUBAACbsLRH5ccff9TTTz+tU6dO6e6771b9+vW1ZcsWfu0XAABIsjioLF682MrNAwAAm7P8PioAAAA3QlABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2RVABAAC2VdTqAgAgt7SfvsnqEgqt5f0bWV0CCih6VAAAgG0RVAAAgG0RVAAAgG0RVAAAgG0RVAAAgG25HVR27typvXv3Ol//5z//UadOnfT3v/9dmZmZuVocAAAo3NwOKi+88IIOHjwoSTpy5Iieeuop+fr66rPPPtOwYcNyvUAAAFB4uR1UDh48qHvvvVeS9Nlnn6lJkyZatGiR5s+fryVLluR6gQAAoPByO6gYY5SVlSVJWr16tdq0aSNJCg8P16lTp3K3OgAAUKi5HVRiYmI0btw4LVy4UBs2bFDbtm0lScnJySpZsmSuFwgAAAovt4PKtGnTtHPnTvXr10+vvvqqIiMjJUmff/65GjRokOsFAgCAwsvt3/qpWbOmy1U/V02aNEkeHh65UhQAAIB0Cz0qKSkp+vHHH52vt23bpkGDBunDDz+Up6dnrhYHAAAKN7eDSpcuXbRu3TpJ0okTJ9SyZUtt27ZNf//73zVmzJhcLxAAABRebgeV77//XvXq1ZMkffrpp6pevbo2b97svEQZAAAgt7gdVC5duiQvLy9Jf1ye3KFDB0lS1apVdfz48dytDgAAFGpuB5Vq1app5syZ2rhxo1atWqWHH35YkvTzzz8rNDQ01wsEAACFl9tB5a233tKsWbPUrFkzPf3006pVq5YkadmyZc5TQgAAALnB7aDSrFkznTp1SqdOndLcuXOd059//nnNnDnzlguZOHGiHA6HBg0adMttAACAgsXt+6hIkoeHhy5fvqxNmzbJ4XCocuXKKl++/C0XsX37ds2ePVs1a9a85TYAAEDB43aPyvnz59WzZ0+FhYWpSZMmaty4sUqXLq1evXrpwoULbhdw7tw5de3aVXPmzFFISIjb6wMAgILL7aASFxenDRs2aPny5Tp79qzOnj2r//znP9qwYYOGDBnidgEvvfSS2rZtqwcffPCmy2ZkZCgtLc3lAQAACi63T/0sWbJEn3/+uZo1a+ac1qZNG/n4+OiJJ57QjBkzctzW4sWLtXPnTm3fvj1Hy0+cOFGjR492t2QAAHCHcrtH5cKFC9f9leQSJUq4deonJSVFAwcO1EcffSRvb+8crTNixAilpqY6HykpKTneHgAAuPO4HVRiY2M1cuRIXbx40Tnt999/1+jRoxUbG5vjduLj43Xy5EnVqVNHRYsWVdGiRbVhwwa9++67Klq0qK5cuZJtHS8vLwUGBro8AABAweX2qZ933nlHDz/8sO655x7VqlVLDodDu3fvlre3t1auXJnjdlq0aJHtV5ife+45Va1aVa+88gq/xAwAANwPKtWrV9ehQ4f00Ucf6cCBAzLG6KmnnlLXrl3l4+OT43YCAgJUvXp1l2l+fn4KDQ3NNh0AABROt3QfFR8fH/Xp0ye3awEAAHCRo6CybNmyHDd49UcKb8X69etveV0AAFDw5CiodOrUKUeNORyO6w6CBQAAuBU5CipZWVl5XQcAAEA2bl+eDAAAkF8IKgAAwLYIKgAAwLYIKgAAwLYIKgAAwLZydNVPWlpajhvk93cAAEBuyVFQCQ4OlsPhyFGD3EcFAADklhwFlXXr1jmfHz16VMOHD1ePHj2cv5b83XffacGCBZo4cWLeVAkAAAqlHAWVpk2bOp+PGTNGU6ZM0dNPP+2c1qFDB9WoUUOzZ89W9+7dc79KAABQKLk9mPa7775TTExMtukxMTHatm1brhQFAAAg3UJQCQ8P18yZM7NNnzVrlsLDw3OlKAAAACmHp36uNXXqVD366KNauXKl6tevL0nasmWLkpKStGTJklwvEAAAFF5u96i0adNGBw8eVIcOHXT69Gn99ttv6tixow4ePKg2bdrkRY0AAKCQcrtHRfrj9M+ECRNyuxYAAAAXt3Rn2o0bN+qZZ55RgwYN9NNPP0mSFi5cqE2bNuVqcQAAoHBzO6gsWbJErVq1ko+Pj3bu3KmMjAxJUnp6Or0sAAAgV7kdVMaNG6eZM2dqzpw58vT0dE5v0KCBdu7cmavFAQCAws3toJKYmKgmTZpkmx4YGKizZ8/mSlEAAADSLQSVsLAwHT58ONv0TZs2qUKFCrlSFAAAgHQLQeWFF17QwIEDtXXrVjkcDv3888/6+OOPNXToUL344ot5USMAACik3L48ediwYUpNTVXz5s118eJFNWnSRF5eXho6dKj69euXFzUCAIBC6pbuozJ+/Hi9+uqr2r9/v7KyshQdHS1/f//crg0AABRybp/6+fDDD5WQkCBfX1/FxMSoXr168vf318WLF/Xhhx/mRY0AAKCQcjuo9OjRQ/Xq1cv2uz6pqal67rnncq0wAACAW7oz7ejRo9WtWzeNGjUql8sBAAD4P7cUVJ555hmtXbtWs2bN0mOPPabff/89t+sCAABwP6g4HA5JUv369bV161YdPnxYDRo00NGjR3O7NgAAUMi5HVSMMc7nZcuW1ebNm1W+fHm1bNkyVwsDAABwO6iMHDnS5VJkX19fLV26VIMHD77urfUBAABuldv3URk5cuR1p48ePfq2iwHyQ/vpm6wuodBa3r+R1SUAuMPkKKgsW7ZMrVu3lqenp5YtW3bD5RwOh9q3b59rxQEAgMItR0GlU6dOOnHihEqUKKFOnTrdcDmHw6ErV67kWnEAAKBwy1FQycrKuu5zAACAvHRL91EBAADIDznqUXn33Xdz3OCAAQNuuRgAAIBr5SioTJ06NUeNORwOggoAAMg1OQoqycnJeV0HAABANoxRAQAAtuX2Dd8k6ccff9SyZct07NgxZWZmusybMmVKrhQGAADgdlBZs2aNOnTooIiICCUmJqp69eo6evSojDG677778qJGAABQSLl96mfEiBEaMmSIvv/+e3l7e2vJkiVKSUlR06ZN9fjjj+dFjQAAoJByO6gkJCSoe/fukqSiRYvq999/l7+/v8aMGaO33nor1wsEAACFl9tBxc/PTxkZGZKk0qVLKykpyTnv1KlTbrU1Y8YM1axZU4GBgQoMDFRsbKy+/vprd0sCAAAFlNtjVOrXr69vv/1W0dHRatu2rYYMGaK9e/fqiy++UP369d1q65577tGbb76pyMhISdKCBQvUsWNH7dq1S9WqVXO3NAAAUMC4HVSmTJmic+fOSZJGjRqlc+fO6ZNPPv1CI9AAABblSURBVFFkZGSObwx31Z9/aXn8+PGaMWOGtmzZQlABAADuB5UKFSo4n/v6+ur999/PlUKuXLmizz77TOfPn1dsbOx1l8nIyHCedpKktLS0XNk2AACwp1u6j8pV586dy/ZryoGBgW61sXfvXsXGxurixYvy9/fX0qVLFR0dfd1lJ06cqNGjR99yvQAA4M7i9mDa5ORktW3bVn5+fgoKClJISIhCQkIUHByskJAQtwuoUqWKdu/erS1btuhvf/ubunfvrv3791932REjRig1NdX5SElJcXt7AADgzuF2j0rXrl0lSXPnzlXJkiXlcDhuq4BixYo5B9PGxMRo+/bteueddzRr1qxsy3p5ecnLy+u2tgcAAO4cbgeVPXv2KD4+XlWqVMmLemSMcRmHAgAACi+3g0rdunWVkpKSK0Hl73//u1q3bq3w8HClp6dr8eLFWr9+vVasWHHbbQMAgDuf20Hln//8p/r27auffvpJ1atXl6enp8v8mjVr5ritX375Rd26ddPx48cVFBSkmjVrasWKFWrZsqW7ZQEAgALI7aDy66+/KikpSc8995xzmsPhkDFGDodDV65cyXFbH3zwgbubBwAAhYjbQaVnz56qXbu2/vWvf+XKYFoAAIAbcTuo/PDDD1q2bJnzSh0AAIC84vZ9VB544AH973//y4taAAAAXLjdo9K+fXsNHjxYe/fuVY0aNbINpu3QoUOuFQcAAAo3t4NK3759JUljxozJNs/dwbQAAAB/xe2g8uff9gEAAMgrbo1RuXz5sooWLarvv/8+r+oBAABwciuoFC1aVOXKleP0DgAAyBduX/Xz2muvacSIETp9+nRe1AMAAODk9hiVd999V4cPH1bp0qVVrlw5+fn5uczfuXNnrhUHAAAKN7eDSqdOnfKiDgAAgGzcDiojR47MizoAAACycTuoXBUfH6+EhAQ5HA5FR0erdu3auVkXAACA+0Hl5MmTeuqpp7R+/XoFBwfLGKPU1FQ1b95cixcv1t13350XdQIAgELI7at++vfvr7S0NO3bt0+nT5/WmTNn9P333ystLU0DBgzIixoBAEAh5XaPyooVK7R69WpFRUU5p0VHR+sf//iHHnrooVwtDgAAFG5u96hkZWVl+yFCSfL09OT2+gAAIFe5HVQeeOABDRw4UD///LNz2k8//aTBgwerRYsWuVocAAAo3NwOKu+9957S09NVvnx5VaxYUZGRkYqIiFB6erqmT5+eFzUCAIBCyu0xKuHh4dq5c6dWrVqlAwcOyBij6OhoPfjgg3lRHwAAKMRu+T4qLVu2VMuWLXOzFgAAABe3FFTWrFmjNWvW6OTJk9kG0M6dOzdXCgMAAHA7qIwePVpjxoxRTEyMwsLC5HA48qIuAAAA94PKzJkzNX/+fHXr1i0v6gEAAHBy+6qfzMxMNWjQIC9qAQAAcOF2UOndu7cWLVqUF7UAAAC4cPvUz8WLFzV79mytXr1aNWvWzHaX2ilTpuRacQAAoHBzO6js2bNH9957ryTp+++/d5nHwFoAAJCb3A4q69aty4s6AAAAsnF7jAoAAEB+IagAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbIqgAAADbsjSoTJw4UXXr1lVAQIBKlCihTp06KTEx0cqSAACAjVgaVDZs2KCXXnpJW7Zs0apVq3T58mU99NBDOn/+vJVlAQAAmyhq5cZXrFjh8nrevHkqUaKE4uPj1aRJE4uqAgAAdmFpUPmz1NRUSVLx4sWvOz8jI0MZGRnO12lpaflSFwAAsIZtBtMaYxQXF6dGjRqpevXq111m4sSJCgoKcj7Cw8PzuUoAAJCfbBNU+vXrpz179uhf//rXDZcZMWKEUlNTnY+UlJR8rBAAAOQ3W5z66d+/v5YtW6ZvvvlG99xzzw2X8/LykpeXVz5WBgAArGRpUDHGqH///lq6dKnWr1+viIgIK8sBAAA2Y2lQeemll7Ro0SL95z//UUBAgE6cOCFJCgoKko+Pj5WlAQBsZMrZgVaXUIjFW7p1S8eozJgxQ6mpqWrWrJnCwsKcj08++cTKsgAAgE1YfuoHAADgRmxz1Q8AAMCfEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtEVQAAIBtFbW6AADILVPODrS6hEIs3uoCUEDRowIAAGyLoAIAAGyLoAIAAGyLoAIAAGyLoAIAAGyLq34AALb3cslLVpdQaP3b4u3TowIAAGyLoAIAAGyLoAIAAGyLMSoACgzGMVjH6nEMKLjoUQEAALZlaY/KN998o0mTJik+Pl7Hjx/X0qVL1alTJytLAgDY0EsfX7a6hMLreWs3b2lQOX/+vGrVqqXnnntOjz76qJWlACgA+DKzkMVfZii4LA0qrVu3VuvWra0sAQAA2NgdNZg2IyNDGRkZztdpaWkWVgMAAPLaHRVUJk6cqNGjR+fb9lY1jc63bcFVyw3786ztAZ/TR22Z/nl3XAEUTHfUVT8jRoxQamqq85GSkmJ1SQAAIA/dUT0qXl5e8vLysroMAACQT+6oHhUAAFC4WNqjcu7cOR0+fNj5Ojk5Wbt371bx4sVVtmxZCysDAAB2YGlQ2bFjh5o3b+58HRcXJ0nq3r275s+fb1FVAADALiwNKs2aNZMxxsoSAACAjTFGBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2BZBBQAA2JblQeX9999XRESEvL29VadOHW3cuNHqkgAAgE1YGlQ++eQTDRo0SK+++qp27dqlxo0bq3Xr1jp27JiVZQEAAJuwNKhMmTJFvXr1Uu/evRUVFaVp06YpPDxcM2bMsLIsAABgE0Wt2nBmZqbi4+M1fPhwl+kPPfSQNm/efN11MjIylJGR4XydmpoqSUpLS8uTGs9fvpIn7eLm8uqYShxXK+XlcZU4tlbi2BZceXFsr7ZpjLnpspYFlVOnTunKlSsqWbKky/SSJUvqxIkT111n4sSJGj16dLbp4eHheVIjLBQUZHUFyAsc14KLY1tw5eGxTU9PV9BN2rcsqFzlcDhcXhtjsk27asSIEYqLi3O+zsrK0unTpxUaGnrDdQqjtLQ0hYeHKyUlRYGBgVaXg1zEsS2YOK4FF8f2+owxSk9PV+nSpW+6rGVB5a677pKHh0e23pOTJ09m62W5ysvLS15eXi7TgoOD86zGO11gYCBvjAKKY1swcVwLLo5tdjfrSbnKssG0xYoVU506dbRq1SqX6atWrVKDBg0sqgoAANiJpad+4uLi1K1bN8XExCg2NlazZ8/WsWPH1LdvXyvLAgAANuExatSoUVZtvHr16goNDdWECRM0efJk/f7771q4cKFq1aplVUkFhoeHh5o1a6aiRS0fhoRcxrEtmDiuBRfH9vY4TE6uDQIAALCA5bfQBwAAuBGCCgAAsC2CCgAAsC2Cyh1u/vz5N72XzKhRo3TvvffmU0XIqWbNmmnQoEFWl4ECoHz58po2bZrVZeA6+Py9fQQVoABav369HA6Hzp49a3UpQKE2dOhQrVmzxuoy7mhcKwUAQB7x9/eXv7+/1WXc0ehRsVh6erq6du0qPz8/hYWFaerUqS6nBM6cOaNnn31WISEh8vX1VevWrXXo0KG/bPPNN99UyZIlFRAQoF69eunixYvZlpk3b56ioqLk7e2tqlWr6v3333fOO3r0qBwOh7744gs1b95cvr6+qlWrlr777rvc3Xno8uXL6tevn4KDgxUaGqrXXnvN+WuimZmZGjZsmMqUKSM/Pz/df//9Wr9+vXPdH374Qe3bt1dISIj8/PxUrVo1ffXVVzp69KiaN28uSQoJCZHD4VCPHj0s2LvCJzfez0uWLFG1atXk5eWl8uXL6+2333aZf/LkSbVv314+Pj6KiIjQxx9/nG/7Vxg1a9ZMAwYM0LBhw1S8eHGVKlVK195+7NixY+rYsaP8/f0VGBioJ554Qr/88otz/p9P/axfv1716tWTn5+fgoOD1bBhQ/3www86evSoihQpoh07drhsf/r06SpXrlyOfmW4wDKwVO/evU25cuXM6tWrzd69e03nzp1NQECAGThwoDHGmA4dOpioqCjzzTffmN27d5tWrVqZyMhIk5mZaYwxZt68eSYoKMjZ3ieffGKKFStm5syZYw4cOGBeffVVExAQYGrVquVcZvbs2SYsLMwsWbLEHDlyxCxZssQUL17czJ8/3xhjTHJyspFkqlatar788kuTmJhoHnvsMVOuXDlz6dKlfPzrFGxNmzY1/v7+ZuDAgebAgQPmo48+Mr6+vmb27NnGGGO6dOliGjRoYL755htz+PBhM2nSJOPl5WUOHjxojDGmbdu2pmXLlmbPnj0mKSnJLF++3GzYsMFcvnzZLFmyxEgyiYmJ5vjx4+bs2bNW7mqhcbvv5x07dpgiRYqYMWPGmMTERDNv3jzj4+Nj5s2b59xG69atTfXq1c3mzZvNjh07TIMGDYyPj4+ZOnWqFbtc4DVt2tQEBgaaUaNGmYMHD5oFCxYYh8Nh/vvf/5qsrCxTu3Zt06hRI7Njxw6zZcsWc99995mmTZs61x85cqTz8/fSpUsmKCjIDB061Bw+fNjs37/fzJ8/3/zwww/GGGNatmxpXnzxRZft165d27zxxhv5tr92RFCxUFpamvH09DSfffaZc9rZs2eNr6+vGThwoDl48KCRZL799lvn/FOnThkfHx/z6aefGmOyB5XY2FjTt29fl+3cf//9LkElPDzcLFq0yGWZsWPHmtjYWGPM/wWVf/7zn875+/btM5JMQkJCLuw5jPnjAzAqKspkZWU5p73yyismKirKHD582DgcDvPTTz+5rNOiRQszYsQIY4wxNWrUMKNGjbpu2+vWrTOSzJkzZ/JuB+AiN97PXbp0MS1btnRp9+WXXzbR0dHGGGMSExONJLNlyxbn/ISEBCOJoJJHmjZtaho1auQyrW7duuaVV14x//3vf42Hh4c5duyYc97Vz8pt27YZY1yDym+//WYkmfXr1193W5988okJCQkxFy9eNMYYs3v3buNwOExycnIe7Nmdg1M/Fjpy5IguXbqkevXqOacFBQWpSpUqkqSEhAQVLVpU999/v3N+aGioqlSpooSEhOu2mZCQoNjYWJdp177+9ddflZKSol69ejnPnfr7+2vcuHFKSkpyWa9mzZrO52FhYZL+6HZG7qlfv74cDofzdWxsrA4dOqQdO3bIGKPKlSu7HKcNGzY4j9OAAQM0btw4NWzYUCNHjtSePXus2g0od97PCQkJatiwoUu7DRs21KFDh3TlyhVnGzExMc75VatW5Vfk89i1n4XSH5+HJ0+eVEJCgsLDwxUeHu6cFx0dreDg4Ot+RhcvXlw9evRQq1at1L59e73zzjs6fvy4c36nTp1UtGhRLV26VJI0d+5cNW/eXOXLl8+bHbtDEFQsZP7/c47XflFdO93c4JykMSbbOjmVlZUlSZozZ452797tfHz//ffasmWLy7Kenp7O51e3d3V95D0PDw/Fx8e7HKeEhAS98847kqTevXvryJEj6tatm/bu3auYmBhNnz7d4qoLr9x4P1/vvX3tejfaBvLWtZ+F0h9//6ysrBt+Fv/VZ/S8efP03XffqUGDBvrkk09UuXJl52dvsWLF1K1bN82bN0+ZmZlatGiRevbsmfs7dIchqFioYsWK8vT01LZt25zT0tLSnIProqOjdfnyZW3dutU5/7ffftPBgwcVFRV13TajoqKyBY5rX5csWVJlypTRkSNHFBkZ6fKIiIjIzd1DDlzvWFWqVEm1a9fWlStXdPLkyWzHqVSpUs7lw8PD1bdvX33xxRcaMmSI5syZI+mPDzxJunLlSv7tTCGXG+/n6Ohobdq0yaXdzZs3q3LlyvLw8FBUVJQuX77sMuAyMTGRy9AtEh0drWPHjiklJcU5bf/+/UpNTb3hZ7Qk1a5dWyNGjNDmzZtVvXp1LVq0yDmvd+/eWr16td5//31dunRJjzzySJ7uw52Ay5MtFBAQoO7du+vll19W8eLFVaJECY0cOVJFihSRw+FQpUqV1LFjR/Xp00ezZs1SQECAhg8frjJlyqhjx47XbXPgwIHq3r27YmJi1KhRI3388cfat2+fKlSo4Fxm1KhRGjBggAIDA9W6dWtlZGRox44dOnPmjOLi4vJr9yEpJSVFcXFxeuGFF7Rz505Nnz5db7/9tipXrqyuXbvq2Wef1dtvv63atWvr1KlTWrt2rWrUqKE2bdpo0KBBat26tSpXrqwzZ85o7dq1zg/HcuXKyeFw6Msvv1SbNm3k4+PDJZJ5LDfez0OGDFHdunU1duxYPfnkk/ruu+/03nvvOa/Kq1Klih5++GH16dNHs2fPVtGiRTVo0CD5+PhYueuF1oMPPqiaNWuqa9eumjZtmi5fvqwXX3xRTZs2dTk9d1VycrJmz56tDh06qHTp0kpMTNTBgwf17LPPOpeJiopS/fr19corr6hnz54cW4mrfqyWlpZmunTpYnx9fU2pUqXMlClTTL169czw4cONMcacPn3adOvWzQQFBRkfHx/TqlUr51UfxmQfTGuMMePHjzd33XWX8ff3N927dzfDhg1zGUxrjDEff/yxuffee02xYsVMSEiIadKkifniiy+MMf83mHbXrl3O5c+cOWMkmXXr1uXRX6Lwadq0qXnxxRdN3759TWBgoAkJCTHDhw93Dq7NzMw0b7zxhilfvrzx9PQ0pUqVMp07dzZ79uwxxhjTr18/U7FiRePl5WXuvvtu061bN3Pq1Cln+2PGjDGlSpUyDofDdO/e3YpdLHRu9/1sjDGff/65iY6ONp6enqZs2bJm0qRJLvOPHz9u2rZta7y8vEzZsmXNhx9+aMqVK8dg2jzStGlT51VbV3Xs2NH5nvrhhx9Mhw4djJ+fnwkICDCPP/64OXHihHPZawfTnjhxwnTq1MmEhYWZYsWKmXLlypk33njDXLlyxaX9Dz74wGVAbmHnMKYwX5xtP+fPn1eZMmX09ttvq1evXlaXA+A28H7GrRg/frwWL16svXv3Wl2KLXDqx2K7du3SgQMHVK9ePaWmpmrMmDGSdMNTOwDsi/czbse5c+eUkJCg6dOna+zYsVaXYxsEFRuYPHmyEhMTVaxYMdWpU0cbN27UXXfdZXVZAG4B72fcqn79+ulf//qXOnXqxNU+1+DUDwAAsC0uTwYAALZFUAEAALZFUAEAALZFUAEAALZFUAEAALZFUAEAALZFUAEAALZFUAEAALZFUAEAALb1/wEa8YjmKUX3UwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def div_first(x):\n",
    "    return [*map(lambda h: h/x[0],x)]\n",
    "labels=[\"golden\",\"best\",\"good\",\"noisy\"]\n",
    "plt.bar(labels,div_first(loss_arc),alpha=0.8)\n",
    "plt.bar(labels,div_first(loss_add),alpha=0.8)\n",
    "plt.bar(labels,div_first(loss_focal),alpha=0.8)\n",
    "plt.bar(labels,div_first(loss_cce),alpha=0.8)\n",
    "plt.legend([\"arcmargin\",\"addmargin\",\"focal\",\"cce\"])\n",
    "plt.ylabel(\"normalized loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f1da79",
   "metadata": {
    "id": "255aa34a"
   },
   "source": [
    "基本arcmargin與addmargin可以讓loss數值對錯誤答案敏感化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6278286a",
   "metadata": {
    "id": "72ox649ear5b"
   },
   "source": [
    "## 3.參考資料\n",
    "* [Chen, W. Y., Liu, Y. C., Kira, Z., Wang, Y. C. F., & Huang, J. B. (2019). A closer look at few-shot classification. arXiv preprint arXiv:1904.04232.](https://arxiv.org/abs/1904.04232)\n",
    "    - Baseline++ 原文(台大王鈺強老師團隊)\n",
    "* [Bromley, J., Guyon, I., LeCun, Y., Säckinger, E., & Shah, R. (1993). Signature verification using a\" siamese\" time delay neural network. Advances in neural information processing systems, 6.](https://proceedings.neurips.cc/paper/1993/hash/288cc0ff022877bd3df94bc9360b9c5d-Abstract.html)\n",
    "    - Siamese Networks原文\n",
    "* [Snell, J., Swersky, K., & Zemel, R. S. (2017). Prototypical networks for few-shot learning. arXiv preprint arXiv:1703.05175.](https://arxiv.org/abs/1703.05175)\n",
    "    - Prototypical networks原文\n",
    "* [Lin, T. Y., Goyal, P., Girshick, R., He, K., & Dollár, P. (2017). Focal loss for dense object detection. In Proceedings of the IEEE international conference on computer vision (pp. 2980-2988). ](https://arxiv.org/abs/1708.02002v2)\n",
    "    - Focal Loss原文\n",
    "* [Wang, H., Wang, Y., Zhou, Z., Ji, X., Gong, D., Zhou, J., ... & Liu, W. (2018). Cosface: Large margin cosine loss for deep face recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 5265-5274).](https://arxiv.org/abs/1801.09414)\n",
    "    - CosineFace原文\n",
    "* [Deng, J., Guo, J., Xue, N., & Zafeiriou, S. (2019). Arcface: Additive angular margin loss for deep face recognition. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 4690-4699).](https://arxiv.org/abs/1801.07698)\n",
    "    - ArcFace原文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b988aa",
   "metadata": {
    "id": "e685e4cf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Few Shot Learning- 1 Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
